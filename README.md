# Vision-Language-Model-Kitchen-utensils-

Zero-shot retrieval that matches utensil images to their usage instructions with OpenCLIP ViT-B/32. Uses a fixed set of ChatGPT-authored canonical sentences for 10 classes. Evaluated on 30 images with 90% top-1 accuracy.

## Run in Google Colab
This project is intended to be run in **Google Colab**.

### Quick start (Colab)
1. Open a new Google Colab notebook.
2. Paste the code from `sinfante_Intro_AI_p2_pt2 code.ipynb`.
3. Run every code cell or click "Runtime" -> "Run all"
